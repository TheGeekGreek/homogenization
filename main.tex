\input{header.tex}
\newcommand{\Ascr}{\mathscr{A}}
\newcommand{\pot}{\mathrm{pot}}
\begin{document}

%Remake Tikz-picture
%\tikzset{external/force remake}

\begin{abstract}

\end{abstract}

\title{Estimates of the modeling error generated by homogenization of an elliptic boundary value problem}
\author{Yannis B\"{a}hni}
\address[Yannis B\"{a}hni]{University of Zurich, R\"{a}mistrasse 71, 8006 Zurich}
\email[Yannis B\"{a}hni]{\href{mailto:yannis.baehni@uzh.ch}{yannis.baehni@uzh.ch}}
\thanks{}
\maketitle

\tableofcontents

\section{The Homogenization Problem}
We follow \cite[1--30]{jikov:homogenization:1994}.

\begin{definition}
Let $n \in \mathbb{Z}$, $n \geq 1$, and $\Omega \subseteq \mathbb{R}^n$ be a bounded domain. A vector $v \in (L^1(\Omega))^n$ is said to be the \bld{gradient of a function $u \in L^1(\Omega)$} if
\begin{equation}
\int_\Omega u \frac{\partial \varphi}{\partial x_i}\d \lambda = -\int_\Omega v_i \varphi\d \lambda
\end{equation} 
\noindent for all $\varphi \in \mathscr{C}^\infty_0(\Omega)$ and $i = 1,\dots,n$. The gradient $v$ of $u$ is denoted by $\nabla u$. 
\end{definition}

Define the Sobolev space $H^1(\Omega)$ by
\begin{equation}
H^1(\Omega) := \cbr[0]{u \in L^2(\Omega) : \nabla u \in (L^2(\Omega))^n}.
\end{equation}
$H^1(\Omega)$ equipped with the inner product
\begin{equation}
\langle u_1,u_2 \rangle_{H^1(\Omega)} := \int_\Omega u_1u_2 \d \lambda + \sum_{k = 1}^n\int_\Omega \frac{\partial u_1}{\partial x_k}\frac{\partial u_2}{\partial x_k}\d \lambda 
\end{equation}
\noindent is then a Hilbert space. We are mainly interested in the subspace
\begin{equation}
H^1_0(\Omega) := \overline{\mathscr{C}^\infty_0(\Omega)} \subseteq H^1(\Omega).
\end{equation}
The dual of $H^1_0(\Omega)$ is denoted by $H^{-1}(\Omega)$. We have that $L^2(\Omega) \hookrightarrow H^{-1}(\Omega)$.

\begin{definition}
Let $n \in \mathbb{Z}$, $n \geq 1$, $\Omega \subseteq \mathbb{R}^n$ be a bounded domain and $p \in (L^2(\Omega))^n$. The \bld{divergence of $p$}, written $\div p$, is defined to be an element of $H^{-1}(\Omega)$ satisfying
\begin{equation}
\langle \div p, \varphi \rangle_{H^1(\Omega)} = - \int_\Omega \langle p, \nabla \varphi \rangle_{\mathbb{R}^n} \d \lambda
\end{equation}
\noindent for all $\varphi \in H^1_0(\Omega)$.
\end{definition}

\begin{definition}
Let $n \in \mathbb{Z}$, $n \geq 1$. A constant positive definite matrix $A_0$ is said to be the \bld{homogenized matrix} for a periodic matrix $A \in M_n\del[0]{L^\infty(\mathbb{R}^n)}$ satisfying the condition of ellipticity
\begin{equation}
a_{ij}(x)y_iy_j \geq c\abs[0]{y}^2 \qquad \forall x,y \in \mathbb{R}^n
\label{eq:ellip_cond}
\end{equation}
\noindent and some $c > 0$, if for any bounded domain $\Omega \subseteq \mathbb{R}^n$ and any $f \in H^{-1}(\Omega)$ the solutions $u_\varepsilon$ of the Dirichlet problem 
\begin{equation}
\div(A_\varepsilon \nabla u_\varepsilon) = f \in H^{-1}(\Omega), \qquad u_\varepsilon \in H^1_0(\Omega),
\end{equation}
\noindent where $A_\varepsilon(x) := A(x/\varepsilon)$ possess the following propertiy of convergence:
\begin{equation}
u_\varepsilon \xrightharpoonup[]{H^1_0(\Omega)} u_0, \qquad A_\varepsilon \nabla u_\varepsilon \xrightharpoonup[]{L^2(\Omega)} A_0\nabla u_0,
\end{equation}
\noindent as $\varepsilon \to 0$, where $u_0$ is the solution of the Dirichlet problem
\begin{equation}
\div(A_0 \nabla u_0) = f, \qquad u_0\in H^1_0(\Omega).
\end{equation}
\end{definition}

\begin{theorem}
Let $A \in M_n\del[0]{L^\infty(\mathbb{R}^n)}$ be a periodic matrix satisfying the ellipticity condition \textup{(}\ref{eq:ellip_cond}\textup{)}. Consider the auxiliary periodic problem
\begin{equation}
\div(Av) = 0, \qquad v \in L^2_{\pot}(\Box), \qquad \langle v \rangle = \alpha \in \mathbb{R}^n
\end{equation} 
\noindent and define $A_0$ by
\begin{equation}
\langle Av \rangle = A_0 \alpha.
\end{equation}
Then $A_0$ is a homogenized matrix for $A$.
\label{thm:homogenized}
\end{theorem}

\begin{proof}
See \cite[19]{jikov:homogenization:1994}.
\end{proof}

From the proof of theorem \ref{thm:homogenized} further follows that 
\begin{equation}
A_0 = \langle A(I + \nabla N)\rangle
\end{equation}
\noindent where $\nabla N$ is the matrix with columns $\nabla N_1,\dots,\nabla N_n$ which are solutions of 
\begin{equation}
\div(A(e_k + \nabla N_k)) = 0, \qquad N_k \in H^1(\Box)
\end{equation}
\noindent for $k = 1,\dots,n$.

\begin{example}
	Let $n := 1$ and $\Omega := \intoo{0,1}$. Furthermore, for $\varepsilon > 0$ define
	\begin{equation}
		A_\varepsilon(x) := 2 + \cos\del[2]{\frac{2\pi x}{\varepsilon}}
		\label{eq:A_eps}
	\end{equation}
	\noindent and let
	\begin{equation}
	f(x) := e^{10x}.
	\end{equation}
	From (\ref{eq:A_eps}) we deduce
	\begin{equation}
		A(x) = A_\varepsilon(\varepsilon x) = 2 + \cos(2\pi x).
	\end{equation}
	Now we have to solve
	\begin{equation}
		(AN')' = A'
		\label{eq:N}
	\end{equation}
	\noindent for the periodic solution $N$ such that $\int_0^1 N = 0$. Integrating (\ref{eq:N}) yields
	\begin{equation}
		N'(x) = 1 + \frac{c}{A(x)}
	\end{equation}
	\noindent for some constant $c \in \mathbb{R}$. Hence
	\begin{equation}
		N(x) = \int_0^x N'(t) \d t = \int_0^x \del[2]{1 + \frac{c}{A(t)}}\d t
	\end{equation}
	\noindent and from the periodicity requirement $N(0) = N(1)$ we get that
	\begin{equation}
		1 = - c \int_0^1 \frac{\d x}{A(x)}.
	\end{equation}
	Using \cite[170]{fischer:funktionentheorie:2003} yields
	\begin{align*}
		\int_0^1 \frac{\d x}{A(x)} &= \int_0^1 \frac{\d x}{2 + \cos(2\pi x)} = \frac{1}{2\pi}\int_0^{2\pi} \frac{\d y}{2 + \cos(y)} = 2\sum_{\abs[0]{\zeta} < 1} \res_\zeta \del{\frac{1}{z^2 + 4z + 1}} = \frac{1}{\sqrt{3}}.
	\end{align*}
	Hence
	\begin{equation}
		\boxed{N'(x) = 1 - \frac{\sqrt{3}}{2 + \cos(2\pi x)}.}
	\end{equation}
	\noindent and
	\begin{equation}
		\boxed{N(x) = \int_0^x \del[2]{1 - \frac{\sqrt{3}}{2 + \cos(2\pi t)}} \d t.}
	\end{equation}
	\noindent since 
	\begin{equation}
	\int_0^1 N(x)\d x = \frac{1}{2}\int_0^1\sbr[2]{\int_0^1 \del[2]{1 - \frac{\sqrt{3}}{2 + \cos(2\pi t)}} \d t}\d x = 0
	\end{equation}
	\noindent by the invariance of the integrand under the mapping $t \mapsto 1 - t$. Furthermore
	\begin{equation*}
		A_0 = \int_0^1 A(x) \d x - \int_0^1 A(x)N'(x) \d x = \int_0^1 A(x) \d x - \int_0^1 A(x)\del[2]{1 - \frac{\sqrt{3}}{A(x)}} \d x = \sqrt{3}.
	\end{equation*}
	Then we have to solve
	\begin{equation}
		\del[0]{A_0u'_0}' = -f.
	\end{equation}
	Integration with respect to $x$ yields
	\begin{equation}
		u'_0(x) = -\frac{1}{\sqrt{3}}\frac{1}{10}e^{10x} + c_1
	\end{equation}
	\noindent for some constant $c_1 \in \mathbb{R}$ and thus 
	\begin{equation}
		u_0(x) = -\frac{1}{\sqrt{3}}\frac{1}{100}e^{10x} + c_1x + c_2
	\end{equation}
	\noindent for some constant $c_2 \in \mathbb{R}$. Since $u_0 \in H^1_0(\Omega)$, we have that $u_0(0) = u_0(1) = 0$ and thus we get the linear system
	\begin{equation}
		-\frac{1}{\sqrt{3}}\frac{1}{100} + c_2 = 0 \qquad\qquad  -\frac{1}{\sqrt{3}}\frac{1}{100}e^{10} + c_1 + c_2 = 0.
		\label{eq:linsys}
	\end{equation}
	\noindent Solving (\ref{eq:linsys}) yields
	\begin{equation}
		\boxed{u_0(x) = \frac{1}{\sqrt{3}}\frac{1}{100} \del[1]{(e^{10} - 1)x + 1 - e^{10x}}.}
	\end{equation}
	Since $\partial \Omega = \cbr[0]{0,1}$ it is easily seen that
	\begin{equation}
	\psi_\varepsilon(x) = \min\del[0]{1,\varepsilon^{-1}\min\del[0]{x,1 - x}}
	\end{equation}
	\noindent and so
	\begin{equation}
		\boxed{w_\varepsilon^1(x) = u_0(x) - \varepsilon \min\del[0]{1,\varepsilon^{-1}\min\del[0]{x,1 - x}}N(\varepsilon^{-1}x)u'_0(x) \qquad x \in \Omega.}	
	\end{equation}
	Lastly we have to solve
	\begin{equation}
	(A_\varepsilon u_\varepsilon')' = -f.
	\end{equation}
	Integration with respect to $x$ yields
	\begin{equation}
	u_\varepsilon'(x) = \frac{1}{A_\varepsilon(x)}\del[1]{c - \frac{1}{10}e^{10x}}
	\end{equation}
	\noindent for some $c \in \mathbb{R}$. Since $u_\varepsilon \in H^1_0(\Omega)$, we have that 
	\begin{equation}
	u_\varepsilon(x) = \int_0^x \frac{1}{A_\varepsilon(t)}\del[1]{c - \frac{1}{10}e^{10t}}\d t
	\end{equation}
	\noindent and from $u_\varepsilon(1) = 0$ we deduce
	\begin{equation}
	\boxed{u_\varepsilon(x) = \frac{1}{10}\int_0^x \frac{1}{A_\varepsilon(t)}\del[2]{\int_0^1 \frac{e^{10s}}{A_\varepsilon(s)}\d s \del[2]{\int_0^1 \frac{\d s}{A_\varepsilon(s)}}^{-1} - e^{10t}}\d t.}
	\end{equation}
	In figure \ref{fig:ex_2_plots} we see the approximations of $u_\varepsilon$ by $w_\varepsilon^1$. One observes that the approximation is even good for a relatively large choice of $\varepsilon$. 
	
	\begin{figure}[h!tb]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/u_eps_w_1_eps_1.pdf}
        \caption{$\varepsilon = 0.2$}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/u_eps_w_1_eps_2.pdf}
        \caption{$\varepsilon = 0.1$}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/u_eps_w_1_eps_3.pdf}
        \caption{$\varepsilon = 0.05$}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/u_eps_w_1_eps_4.pdf}
        \caption{$\varepsilon = 0.01$}
    \end{subfigure}
    \caption{Plot of the approximations $w_\varepsilon^1$ of $u_\varepsilon$ for certain values of $\varepsilon$.}
    \label{fig:ex_2_plots}
	\end{figure}
	
	Now we want to numerically check the error estimate
	\begin{equation}
	\norm[0]{u_\varepsilon - w_\varepsilon^1}_{H^1(\Omega)} \leq c \sqrt{\varepsilon}.
	\end{equation}
	For that we have to calculate $(w_\varepsilon^1)'$ which involves $\psi_\varepsilon'$. This is the only difficult task. Using the notion of weak derivatives and $\min(f,g) = f + g - \abs[0]{f - g}$ we get that
	\begin{equation}
	\boxed{\psi_\varepsilon'(x) = -\frac{1}{2\varepsilon}\sgn(2x - 1)\del[2]{1 + \sgn\del[2]{1 - \frac{1}{2\varepsilon}(1 - \abs[0]{2x - 1})}}.}
	\end{equation}
	
	In figure \ref{fig:ex_2_plots_d} we see the approximation of $u_\varepsilon'$ by $(w_\varepsilon^1)'$ for certain values of $\varepsilon$. One observes that the approximations are not as quite as good as the one of $u_\varepsilon$ by $w_\varepsilon^1$.
	
	\begin{figure}[h!tb]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/du_eps_dw_1_eps_1.pdf}
        \caption{$\varepsilon = 0.2$}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/du_eps_dw_1_eps_2.pdf}
        \caption{$\varepsilon = 0.1$}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/du_eps_dw_1_eps_3.pdf}
        \caption{$\varepsilon = 0.05$}
    \end{subfigure}
    ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc. 
      %(or a blank line to force the subfigure onto a new line)
    \begin{subfigure}[b]{0.5\textwidth}
        \includegraphics[width=\textwidth]{src/img/du_eps_dw_1_eps_4.pdf}
        \caption{$\varepsilon = 0.01$}
    \end{subfigure}
    \caption{Plot of the approximations $(w_\varepsilon^1)'$ of $u_\varepsilon'$ for certain values of $\varepsilon$.}
    \label{fig:ex_2_plots_d}
	\end{figure}
	
	\begin{figure}[h!tb]
	\includegraphics[width=\textwidth]{src/img/error.pdf}
	\caption{Plot of the error $\norm[0]{u_\varepsilon - w_\varepsilon^1}_{H^1(\Omega)}$.}
	\label{fig:error}
	\end{figure}
\end{example}
%Appendix
\appendix

\section{Listings}
\lstinputlisting{src/example.m}

\printbibliography
\end{document}
